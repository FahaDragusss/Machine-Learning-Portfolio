# ğŸ“Œ ElasticNet Regression from Scratch

This module implements **ElasticNet Regression** from scratch using only NumPy â€” combining both **L1 (Lasso)** and **L2 (Ridge)** regularization. The ElasticNet algorithm helps balance coefficient shrinkage and sparsity, offering robustness on datasets with multicollinearity or when neither Lasso nor Ridge alone performs optimally.

While the model performs **competitively**, it does **not outperform** traditional linear regression on this dataset and was not deployed for demonstration.

---

## ğŸŒ Live Demo

> Try the model directly here:  
ğŸ”— [ElasticNet Regression on Hugging Face]

---

## ğŸ§  Key Features

- âœ… Complete implementation using only **NumPy**
- âœ… Trains ElasticNet using **gradient descent**
- âœ… Combines **L1 and L2** penalties to balance between Lasso and Ridge
- âœ… Evaluated on the Auto-MPG dataset
- âœ… Visualized residuals and prediction quality
- âœ… **Deployed** using Streamlit and Hugging Face 

Note : Even though this model didnâ€™t outperform others, I deployed it to demonstrate how different forms of regularization affect model behavior â€” both mathematically and practically.

---

## ğŸ“ Directory Structure

ElasticNet/
â”‚
â”œâ”€â”€ Analysis and Visualization/ # Residuals, prediction plots, training curves
â”‚
â”œâ”€â”€ DevSet/ # Early tests on synthetic data
â”‚
â”œâ”€â”€ EDA-&-Preprocessing/ # Cleaned data and preprocessing notebooks
â”‚
â”œâ”€â”€ Implementation/ # Model training and loss calculation
â”‚ â””â”€â”€ ElasticNet Model.ipynb
â”‚
â”œâ”€â”€ Results/ # Final evaluation plots
â”‚
â””â”€â”€ README.md


---

## ğŸ“Š Model Performance Summary

### âœ… Generalization:
- **Test RÂ²**: `0.8997`  
- **Train RÂ²**: `0.8450`  
- The model generalizes well to unseen data.

---

### âœ… Error Metrics:
- **MSE** increased from `5.6752` â†’ `5.6817`  
- This is only a **0.06% increase** in average prediction error (based on RMSE).  
- Both **MSE and MAE** dropped on train/test sets during training, indicating **smooth convergence**.

---

### âœ… RÂ² Score Trends:
- **Train RÂ²**: `0.8451 â†’ 0.8450`  
- **Test RÂ²**: `0.8999 â†’ 0.8997`  
- These minimal changes confirm the model reached a **stable solution** with no meaningful overfitting.

---

## ğŸ“ˆ Evaluation Plots

### ğŸ“‰ Residuals Plot  
Residuals are randomly scattered around the **y = 0** line, indicating the model's errors have no pattern â€” a positive sign for model assumptions.

![Residuals Plot](./Results/residuals_EN.png)

---

### ğŸ“Š Actual vs Predicted  
Points lie close to the **diagonal (y = x)** line, showing strong predictive power and alignment between model output and real data.

![Actual vs Predicted](./Results/Actual_vs_predicted_EN.png)

---


### ğŸ“ˆ Summary:
The ElasticNet implementation performs reliably but does not outperform traditional linear regression or its individual regularized counterparts (Ridge, Lasso) on this dataset.

---

## ğŸ“ Takeaways

- ElasticNet serves as a **hybrid regularization model**, combining benefits of Lasso and Ridge.
- Ideal for datasets with **many features** or **high multicollinearity** â€” but unnecessary here.
- Deployment was skipped due to **no added benefit** over simpler models.

---

## ğŸ“¬ Contact

Built by **[FahaDragusss](https://github.com/FahaDragusss)**  
Reach out for discussions, collaborations, or feedback.

---

## ğŸ“„ License

This module is licensed under the **MIT License**.
