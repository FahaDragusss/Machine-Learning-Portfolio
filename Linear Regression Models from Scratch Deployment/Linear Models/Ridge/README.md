# ðŸ“Œ Ridge Regression from Scratch (No Deployment)

This module implements **Ridge Regression** from scratch using fully vectorized NumPy, as part of a larger project exploring linear and regularized models.

Unlike the base multiple linear regression model (which was deployed), this Ridge implementation focuses purely on model behavior, convergence, and generalization â€” **not** deployment or flashy demos.

---

## ðŸŒ Live Demo

> Try the model directly here:  
ðŸ”— [Ridge Regression on Hugging Face](https://huggingface.co/spaces/FahaDragusss/Ridge-regression-scratch-streamlit)

---

## ðŸ§  Key Features
- âœ… No scikit-learn training â€” fully written with NumPy  
- âœ… Applied L2 Regularization (Ridge) to reduce overfitting  
- âœ… Modular pipeline for training, testing, and visualizing  
- âœ… Residual & Prediction plots to assess model fitness
- âœ… **Deployed** using Streamlit and Hugging Face 

Note : Even though this model didnâ€™t outperform others, I deployed it to demonstrate how different forms of regularization affect model behavior â€” both mathematically and practically.

---

## ðŸ“Š Dataset
- Dataset: [Auto MPG Dataset](https://www.kaggle.com/datasets/yasserh/auto-mpg-dataset)
- Preprocessing steps:
  - Outlier removal  
  - Feature scaling  
  - Log transformation on skewed variables  
  - Missing values handled  
  - Categorical encoding  

---

## ðŸ§ª Project Structure

Ridge/
â”‚
â”œâ”€â”€ Dataset/ # Processed data
â”‚
â”œâ”€â”€ DevSet/ # Experiments on synthetic datasets
â”‚
â”œâ”€â”€ EDA & Preprocessing/ # Data preparation and analysis notebooks
â”‚
â”œâ”€â”€ Implementation/ # Final training & model code
â”‚
â””â”€â”€ README.md # This file


---

## ðŸ“Š Model Performance Summary

### âœ… Generalization:
- **Test RÂ²**: `0.8998`  
- **Train RÂ²**: `0.8450`  

The model generalizes well. The fact that test RÂ² is even slightly higher than train RÂ² implies **strong performance on unseen data** with no signs of overfitting.

---

### âœ… Error Metrics:
- **Train MSE** increased slightly from `5.6752` to `5.6778`  
- Thatâ€™s only a **0.02% increase in average prediction error**, confirming numerical stability.

Both **MSE** and **MAE** continue to **decline smoothly**, showing no divergence in training.

---

### âœ… RÂ² Score Stability:
- **Train RÂ²**: `0.8451 â†’ 0.8450`  
- **Test RÂ²**: `0.8999 â†’ 0.8998`

No significant RÂ² improvements â€” the optimization path had already reached a good local minimum.

---

### ðŸ“ˆ Summary:
Although Ridge Regression shows stable behavior and generalization, it **does not outperform** the base multiple linear regression model for this dataset. Therefore, it was **not deployed**.

---

## ðŸ“ˆ Evaluation Plots

### ðŸ“‰ Residuals Plot  
Residuals are randomly scattered around the **y = 0** line, indicating the model's errors have no pattern â€” a positive sign for model assumptions.

![Residuals Plot](./Results/residuals_mrr.png)

---

### ðŸ“Š Actual vs Predicted  
Points lie close to the **diagonal (y = x)** line, showing strong predictive power and alignment between model output and real data.

![Actual vs Predicted](./Results/actual_vs_predicted_mrr.png)

---

## ðŸ“š Learnings & Takeaways
- Ridge adds robustness but doesn't guarantee better performance.  
- Even small regularization strengths affect convergence behavior.  
- Model generalization â‰  model superiority â€” metrics must guide deployment choices.  

---

## ðŸ“¬ Contact
Built by **[FahaDragusss](https://github.com/FahaDragusss)**  
Feel free to reach out for collaboration or feedback.

---

## ðŸ“„ License
This module is licensed under the **MIT License**.

