# ğŸ“Œ Multiple Linear Regression from Scratch (Deployed!)

This project is a subset/small step 1 of implementing Linear Regression, Ridge, Lasso, and ElasticNet from scratch using vectorized NumPy.

It is trained on a real-world dataset and is deployed using Streamlit on Hugging Face Spaces.

---

## ğŸ§  Key Features
- âœ… Fully vectorized implementations (no scikit-learn for training)
- âœ… End-to-end workflow: from EDA â†’ preprocessing â†’ training â†’ deployment
- âœ… Animated visualizations to show model behavior
- âœ… Deployed interactive app via Streamlit + Hugging Face

---

## ğŸ”— Live Demo
ğŸ¯ **[ğŸ‘‰ Try the Streamlit App on Hugging Face](https://huggingface.co/spaces/FahaDragusss/MLR-scratch-streamlit)**

---

## ğŸ“Š Dataset
- Dataset: [Auto MPG Dataset](https://www.kaggle.com/datasets/yasserh/auto-mpg-dataset)
- Preprocessing:
  - Handled missing values
  - Feature scaling
  - Log transformation (unskewing)
  - Outlier Handling
  - Exploratory Data Analysis (EDA)

---

## ğŸ§ª Project Structure

```
project/
â”‚
â”œâ”€â”€ Analysis and visualization/    # Generated GIFs and plots
â”œâ”€â”€ app/                           # Streamlit interface
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ model.joblib
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ DevSet/                        # Prototype implementation on synthetic data
â”œâ”€â”€ EDA-&-Preprocessing/
â”‚   â”œâ”€â”€ car-mpg.csv
â”‚   â””â”€â”€ EDA & preprocessing.ipynb
â”œâ”€â”€ Implementation/
â”‚   â”œâ”€â”€ MLR Model.ipynb
â”‚   â””â”€â”€ handled-car-mpg.csv
â”œâ”€â”€ Results/                       # Final visuals for presentation
â””â”€â”€ README.md
```

---

## ğŸš€ How to Run Locally

```bash
# Step 1: Clone the repo
git clone https://github.com/FahaDragusss/Machine-Learning-Portfolio.git

# Step 2: Navigate to app folder
cd Machine-Learning-Portfolio/Linear Regression Models from Scratch Deployment/Multiple Linear Regression/app

# Step 3: Install dependencies
pip install -r requirements.txt

# Step 4: Run the Streamlit app
streamlit run app.py
```

---

## ğŸ“ˆ Training Visualizations

This project includes animations and plots to visualize the training and convergence behavior of models:

---

### ğŸï¸ Regression Line Fitting Animation
Shows how the model adjusts the regression line over time to minimize cost.

![Regression Animation](./Results/regression_animation.gif)

---

### ğŸ“‰ Cost Function Convergence
Visualizes the descent of the cost function over iterations, confirming successful optimization.

- **Left plot**: Iterations â‰¤ 5000  
- **Right plot**: Iterations â‰¥ 6000 up to convergence

![Cost Convergence](./Results/cost_convergence.gif)

---

### ğŸ§  Weights (Theta) Convergence
Demonstrates how model weights (`Î¸`) stabilize over training iterations.

- **Left plot**: Iterations â‰¤ 5000  
- **Right plot**: Iterations â‰¥ 6000 up to convergence

![Weights Convergence](./Results/weights_convergence.gif)

---

## ğŸ“š Learnings & Takeaways
- Gradient descent behaves differently under each regularization type.
- Lasso uses non-differentiable penalties â€” hence not truly gradient-based.
- Visualizing training metrics greatly enhances interpretability.

---

## ğŸ“¬ Contact
Built by **[FahaDragusss](https://github.com/FahaDragusss)**  
Feel free to reach out for collaboration or feedback!

---

## ğŸ“„ License
This project is licensed under the MIT License.
